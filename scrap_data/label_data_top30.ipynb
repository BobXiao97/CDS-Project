{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the file we use to combine and label the songs based on whether a song had ever made it to the top 30 of the chart\n",
    "## Although we did not use this criteria eventually, the data we use now is built upon output of this file as this combines all the unique songs across songs collected for all 3 years and keep the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from os import system\n",
    "from datetime import timedelta, date\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(track_name, hit_list, non_hit_list):\n",
    "    if track_name in hit_list:\n",
    "        return 1\n",
    "    elif track_name in non_hit_list:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1 #indicate something went wrong\n",
    "def update_streams(track_name, highest_stream):\n",
    "    return highest_stream[track_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(hit_song_criteria):\n",
    "    all_filenames = [i for i in glob.glob('feature_*')]\n",
    "    data = pd.concat([pd.read_csv(f) for f in all_filenames ]) #combine all csv\n",
    "    \n",
    "    hit_list = []        # list of hit songs\n",
    "    non_hit_list = []    # list of non hit songs \n",
    "    highest_stream = {}  # highest stream value we can obtain form the data\n",
    "    \n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        if row['Track Name'] not in highest_stream or int(row['Streams']) > int(highest_stream[row['Track Name']]):\n",
    "            highest_stream[row['Track Name']] = row['Streams']\n",
    "        if int(row['Position']) <= hit_song_criteria and row['Track Name'] not in hit_list:\n",
    "            hit_list.append(row['Track Name'])\n",
    "    for index, row in data.iterrows():\n",
    "        if int(row['Position']) > hit_song_criteria and row['Track Name'] not in hit_list and row['Track Name'] not in non_hit_list:\n",
    "            non_hit_list.append(row['Track Name'])\n",
    "    data = data.drop_duplicates(['Track Name'])        \n",
    "    data['Label'] = data['Track Name'].apply(lambda track_name: assign_label(track_name, hit_list, non_hit_list))\n",
    "    data['Streams'] = data['Track Name'].apply(lambda track_name: update_streams(track_name, highest_stream))\n",
    "    del data[\"Position\"]\n",
    "    data = data.sort_values(by = 'Label', ascending=False)\n",
    "    data.to_csv('labeled_spotify_data.csv',index = False)\n",
    "    print(\"Label finished, the labeled file is saved as labeled_spotify_data.csv\")\n",
    "    print(\"number of hit song: \", len(hit_list))\n",
    "    print(\"number of non hit song: \", len(non_hit_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs that managed to once hit top 30 in the list will be considered as hit song\n",
      "Label finished, the labeled file is saved as labeled_spotify_data.csv\n",
      "number of hit song:  1035\n",
      "number of non hit song:  3745\n"
     ]
    }
   ],
   "source": [
    "# songs that managed to hit the top 10 list will be considered as \"hit song\"\n",
    "hit_song_criteria = 30\n",
    "print(\"Songs that managed to once hit top {} in the list will be considered as hit song\".format(hit_song_criteria))\n",
    "label_data(hit_song_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing columns  URL, trackID, type, id, uri, track_href,\n",
      "only essential features kept in labeled_spotify_data_clean.csv\n"
     ]
    }
   ],
   "source": [
    "def remove_redundant_columns(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    col_to_del = [\"URL\", \"trackID\", \"type\", \"id\", \"uri\", \"track_href\"]\n",
    "    print(\"removing columns \",\"URL,\", \"trackID,\", \"type,\", \"id,\", \"uri,\", \"track_href,\")\n",
    "    for col in col_to_del:\n",
    "        try:\n",
    "            del data[col]\n",
    "        except Exceptions as e:\n",
    "            print(e)\n",
    "    data.to_csv('labeled_spotify_data_clean.csv',index = False)\n",
    "    print(\"only essential features kept in labeled_spotify_data_clean.csv\")\n",
    "    \n",
    "remove_redundant_columns('labeled_spotify_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
